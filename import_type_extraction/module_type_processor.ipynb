{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from module_type_generator import ModuleGenerator\n",
    "from gh_query import load_json, gen_json_file, find_current_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of projects: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'author': 'pandas-dev',\n",
       "  'repo': 'pandas',\n",
       "  'repoUrl': 'https://github.com/pandas-dev/pandas',\n",
       "  'stars': 20800,\n",
       "  'forks': 8240},\n",
       " {'author': 'numpy',\n",
       "  'repo': 'numpy-stubs',\n",
       "  'repoUrl': 'https://github.com/numpy/numpy-stubs',\n",
       "  'stars': 149,\n",
       "  'forks': 17}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load list of repositories (same as in TW/DLTPy pipeline)\n",
    "repos = load_json('.././data/mypy-dependents-by-stars.json')\n",
    "gen_json_file('.././data/py_500.json', repos, find_current_repos('.././data/training_repos/', True))\n",
    "repos = load_json('.././data/py_500.json')\n",
    "\n",
    "print(\"number of projects:\", len(repos))\n",
    "repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 491.65it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/import_types\\\\pandas-devpandas-import-types.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Evaldas\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Evaldas\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Evaldas\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Evaldas\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Evaldas\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Evaldas\\Dev\\Work\\Type Predictor\\dl-type-python\\import_type_extraction\\module_type_generator.py\", line 68, in process_project_for_import\n    self.write_project(project)\n  File \"C:\\Users\\Evaldas\\Dev\\Work\\Type Predictor\\dl-type-python\\import_type_extraction\\module_type_generator.py\", line 117, in write_project\n    type_df.to_csv(self.get_project_filename(project), index=False)\n  File \"C:\\Users\\Evaldas\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\generic.py\", line 3228, in to_csv\n    formatter.save()\n  File \"C:\\Users\\Evaldas\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\", line 183, in save\n    compression=self.compression,\n  File \"C:\\Users\\Evaldas\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\common.py\", line 399, in _get_handle\n    f = open(path_or_buf, mode, encoding=encoding, newline=\"\")\nFileNotFoundError: [Errno 2] No such file or directory: '../output/import_types\\\\pandas-devpandas-import-types.csv'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4e0457991d1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[0mmodule_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModuleGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepos_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m \u001b[0mmodule_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_repos_for_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Dev\\Work\\Type Predictor\\dl-type-python\\import_type_extraction\\module_type_generator.py\u001b[0m in \u001b[0;36mprocess_repos_for_types\u001b[1;34m(self, repos_list, jobs, start)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         ParallelExecutor(n_jobs=jobs)(total=len(repos_list))(\n\u001b[1;32m---> 27\u001b[1;33m             delayed(self.process_project_for_import)(i, project) for i, project in enumerate(repos_list, start=start))\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess_project_for_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dev\\Work\\Type Predictor\\dl-type-python\\dltpy\\preprocessing\\utils.py\u001b[0m in \u001b[0;36mtmp\u001b[1;34m(op_iter)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Value %s not supported as bar type\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mjoblib_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbar_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/import_types\\\\pandas-devpandas-import-types.csv'"
     ]
    }
   ],
   "source": [
    "# # Create type extractor to extract types\n",
    "# type_extractor = ModuleExtractor()\n",
    "\n",
    "# def process_project_for_import(i, project):\n",
    "#     \"\"\"\n",
    "#     Processes a single project for import type analysis.\n",
    "#     The function extracts the visible import types for a project,\n",
    "#     creates a dataframe for the project with columns: [author, repo, file, types],\n",
    "#     and saves it in the output directory.\n",
    "    \n",
    "#     TODO: Code adapted from pipeline.py. In the future, it would\n",
    "#     probably be better to extract the common functionality to reduce\n",
    "#     code redundancy in terms of changes.\n",
    "#     \"\"\"\n",
    "#     project_id = f'{project[\"author\"]}/{project[\"repo\"]}'\n",
    "#     print(f'Running pipeline for project {i} {project_id}')\n",
    "\n",
    "#     # TODO: Caching check could be added here\n",
    "    \n",
    "#     # Get directory\n",
    "#     print(f'Filtering for {project_id}...')\n",
    "#     filtered_project_directory = project_filter.filter_directory(os.path.join(repos_dir, project[\"author\"],\n",
    "#                                                                             project[\"repo\"]))\n",
    "    \n",
    "#     print(f'Extracting import typesfor {project_id}...')\n",
    "    \n",
    "#     # Get files recursively from project directory\n",
    "#     file_list = list_files(filtered_project_directory)\n",
    "    \n",
    "#     # Store extracted types as ddictionary {'filename' -> [type_list]}\n",
    "#     extracted_types = {}\n",
    "    \n",
    "#     for filename in file_list:\n",
    "#         # Get import types & add to dictionary\n",
    "#         types = type_extractor.get_types(filename)\n",
    "#         extracted_types[filename] = list(types)\n",
    "\n",
    "#     # Add entry for 'files' in project to contain dicts of filename and types\n",
    "#     project['files'] = [{'filename': filename, 'types': extracted_types[filename] }\n",
    "#                     for filename in file_list]\n",
    "    \n",
    "#     # Write the project as a CSV file\n",
    "#     write_project(project)\n",
    "\n",
    "#     # This can be replaced by the utility method in gh_query.py\n",
    "#     #         if extracted_avl_types:\n",
    "#     #             with open(os.path.join(self.avl_types_dir, f'{project[\"author\"]}_{project[\"repo\"]}_avltypes.txt'), 'w') as f:\n",
    "#     #                 for t in extracted_avl_types:\n",
    "#     #                     f.write(\"%s\\n\" % t)\n",
    "#     #     except KeyboardInterrupt:\n",
    "#     #         quit(1)\n",
    "#     #     except Exception:\n",
    "#     #         print(f'Running pipeline for project {i} failed')\n",
    "#     #         traceback.print_exc()\n",
    "#     #     finally:\n",
    "#     #         self.write_project(project)\n",
    "\n",
    "# def get_project_filename(project) -> str:\n",
    "#     \"\"\"\n",
    "#     Return the filename at which a project import type datafile should be stored.\n",
    "#     :param project: the project dict\n",
    "#     :return: return filename\n",
    "#     \"\"\"\n",
    "#     return os.path.join(output_dir, f\"{project['author']}{project['repo']}-import-types.csv\")\n",
    "    \n",
    "# def write_project(project) -> None:\n",
    "#     \"\"\"\n",
    "#     Writes the project to a CSV file.\n",
    "#     Assumes the project already has a 'files' field which contains\n",
    "#     nested dictionary entries of {'filename', 'types'} for each file.\n",
    "#     If there is no 'files' field, nothing is written; the project is simply skipped.\n",
    "#     \"\"\"\n",
    "#     import_types = []\n",
    "#     columns = ['author', 'repo', 'file', 'types']\n",
    "\n",
    "#     if 'files' in project:\n",
    "#         for file in project['files']:\n",
    "#              type_data = (\n",
    "#                  project['author'],\n",
    "#                  project['repo'],\n",
    "#                  file['filename'],\n",
    "#                  file['types']\n",
    "#              )\n",
    "\n",
    "#              import_types.append(type_data)\n",
    "\n",
    "#     if len(import_types) == 0:\n",
    "#         print(\"Skipped...\")\n",
    "#         return\n",
    "    \n",
    "#     type_df = pd.DataFrame(import_types, columns=columns)\n",
    "#     type_df.to_csv(get_project_filename(project), index=False)\n",
    "\n",
    "# # Process single project for imports\n",
    "# process_project_for_import(0, repos[0])\n",
    "\n",
    "# Initialize repos & output directories\n",
    "repos_dir = \"../data/training_repos\"\n",
    "output_dir = \"../output/import_types\"\n",
    "\n",
    "module_generator = ModuleGenerator(repos_dir, output_dir)\n",
    "\n",
    "module_generator.process_repos_for_types(repos, jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit0c1bf504740848439a4c1321803b5d13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
