{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Evaldas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Evaldas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Evaldas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nt.uname_result', 'os.PathLike', 'os.statvfs_result', 'os.terminal_size', 'joblib.parallel.parallel_backend', 'joblib.logger.PrintTime', 'os._Environ', 'joblib.logger.Logger', 'joblib.parallel.Parallel', 'nt.times_result', 'builtins.error', 'os._wrap_close', 'collections.abc.MutableMapping', 'os.stat_result', 'joblib.memory.Memory', 'joblib.memory.MemorizedResult', 'nt.DirEntry'}\n"
     ]
    }
   ],
   "source": [
    "from module_type_generator import ModuleGenerator\n",
    "from gh_query import load_json, gen_json_file, find_current_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of projects: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'author': 'aio-libs',\n",
       "  'repo': 'create-aio-app',\n",
       "  'repoUrl': 'https://github.com/aio-libs/create-aio-app',\n",
       "  'stars': 123,\n",
       "  'forks': 30}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load list of repositories (same as in TW/DLTPy pipeline)\n",
    "repos = load_json('.././data/mypy-dependents-by-stars.json')\n",
    "gen_json_file('.././data/py_500.json', repos, find_current_repos('.././data/training_repos/', True))\n",
    "repos = load_json('.././data/py_500.json')\n",
    "\n",
    "print(\"number of projects:\", len(repos))\n",
    "repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline for project 0 aio-libs/create-aio-app\n",
      "Filtering for aio-libs/create-aio-app...\n",
      "Extracting import typesfor aio-libs/create-aio-app...\n"
     ]
    }
   ],
   "source": [
    "# # Create type extractor to extract types\n",
    "# type_extractor = ModuleExtractor()\n",
    "\n",
    "# def process_project_for_import(i, project):\n",
    "#     \"\"\"\n",
    "#     Processes a single project for import type analysis.\n",
    "#     The function extracts the visible import types for a project,\n",
    "#     creates a dataframe for the project with columns: [author, repo, file, types],\n",
    "#     and saves it in the output directory.\n",
    "    \n",
    "#     TODO: Code adapted from pipeline.py. In the future, it would\n",
    "#     probably be better to extract the common functionality to reduce\n",
    "#     code redundancy in terms of changes.\n",
    "#     \"\"\"\n",
    "#     project_id = f'{project[\"author\"]}/{project[\"repo\"]}'\n",
    "#     print(f'Running pipeline for project {i} {project_id}')\n",
    "\n",
    "#     # TODO: Caching check could be added here\n",
    "    \n",
    "#     # Get directory\n",
    "#     print(f'Filtering for {project_id}...')\n",
    "#     filtered_project_directory = project_filter.filter_directory(os.path.join(repos_dir, project[\"author\"],\n",
    "#                                                                             project[\"repo\"]))\n",
    "    \n",
    "#     print(f'Extracting import typesfor {project_id}...')\n",
    "    \n",
    "#     # Get files recursively from project directory\n",
    "#     file_list = list_files(filtered_project_directory)\n",
    "    \n",
    "#     # Store extracted types as ddictionary {'filename' -> [type_list]}\n",
    "#     extracted_types = {}\n",
    "    \n",
    "#     for filename in file_list:\n",
    "#         # Get import types & add to dictionary\n",
    "#         types = type_extractor.get_types(filename)\n",
    "#         extracted_types[filename] = list(types)\n",
    "\n",
    "#     # Add entry for 'files' in project to contain dicts of filename and types\n",
    "#     project['files'] = [{'filename': filename, 'types': extracted_types[filename] }\n",
    "#                     for filename in file_list]\n",
    "    \n",
    "#     # Write the project as a CSV file\n",
    "#     write_project(project)\n",
    "\n",
    "#     # This can be replaced by the utility method in gh_query.py\n",
    "#     #         if extracted_avl_types:\n",
    "#     #             with open(os.path.join(self.avl_types_dir, f'{project[\"author\"]}_{project[\"repo\"]}_avltypes.txt'), 'w') as f:\n",
    "#     #                 for t in extracted_avl_types:\n",
    "#     #                     f.write(\"%s\\n\" % t)\n",
    "#     #     except KeyboardInterrupt:\n",
    "#     #         quit(1)\n",
    "#     #     except Exception:\n",
    "#     #         print(f'Running pipeline for project {i} failed')\n",
    "#     #         traceback.print_exc()\n",
    "#     #     finally:\n",
    "#     #         self.write_project(project)\n",
    "\n",
    "# def get_project_filename(project) -> str:\n",
    "#     \"\"\"\n",
    "#     Return the filename at which a project import type datafile should be stored.\n",
    "#     :param project: the project dict\n",
    "#     :return: return filename\n",
    "#     \"\"\"\n",
    "#     return os.path.join(output_dir, f\"{project['author']}{project['repo']}-import-types.csv\")\n",
    "    \n",
    "# def write_project(project) -> None:\n",
    "#     \"\"\"\n",
    "#     Writes the project to a CSV file.\n",
    "#     Assumes the project already has a 'files' field which contains\n",
    "#     nested dictionary entries of {'filename', 'types'} for each file.\n",
    "#     If there is no 'files' field, nothing is written; the project is simply skipped.\n",
    "#     \"\"\"\n",
    "#     import_types = []\n",
    "#     columns = ['author', 'repo', 'file', 'types']\n",
    "\n",
    "#     if 'files' in project:\n",
    "#         for file in project['files']:\n",
    "#              type_data = (\n",
    "#                  project['author'],\n",
    "#                  project['repo'],\n",
    "#                  file['filename'],\n",
    "#                  file['types']\n",
    "#              )\n",
    "\n",
    "#              import_types.append(type_data)\n",
    "\n",
    "#     if len(import_types) == 0:\n",
    "#         print(\"Skipped...\")\n",
    "#         return\n",
    "    \n",
    "#     type_df = pd.DataFrame(import_types, columns=columns)\n",
    "#     type_df.to_csv(get_project_filename(project), index=False)\n",
    "\n",
    "# # Process single project for imports\n",
    "# process_project_for_import(0, repos[0])\n",
    "\n",
    "# Initialize repos & output directories\n",
    "repos_dir = \"../data/training_repos\"\n",
    "output_dir = \"../output/import_types\"\n",
    "\n",
    "module_generator = ModuleGenerator(repos_dir, output_dir)\n",
    "\n",
    "#module_generator.process_project_for_import(0, repos[0])\n",
    "module_generator.process_repos_for_types(repos, jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit0c1bf504740848439a4c1321803b5d13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
